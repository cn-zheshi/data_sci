# 数据科学大作业后端

爬取天涯、观察者网和微博的疫情相关文章的评论，分析疫情下的大众心理，并通过机器学习做出预测。

## 项目进度

- 12.16 创建flask项目框架 完成天涯爬虫（项目框架指一堆空文件夹；
- 12.17 初步完成微博爬虫的爬取评论功能；

## TODO

- 12.13-12.20 完成项目框架的搭建，三个爬虫的整合，并开始进行数据分析；

## 爬虫包接口

`get_all()`返回一个列表，元素分别为文章/帖子/博文的主题、时间、url和评论，其中评论是列表形式。

### usage

调用时导入`util.spiders.<name>`中的`get_all()`函数即可。

微博的爬虫如果想调整一次性爬取的结果数量，请手动调整`urls = find_urls(news_manager, <url>, <max_num>)`中的`max_num`。

### config

天涯的可以直接调用。

微博需要手动配置。配置方法如下：

- 安装`selenium`包，并进行浏览器驱动下载配置，具体请`STFW`；
- 手动修改`util/news_parser.py`中`NewsManager`的`_dynamic`方法中的浏览器驱动路径`executable_path`；
- 手动修改`util/spiders/weibo.py`中`get_all()`函数中的`name`和`passwd`，将其替换为你自己的微博账号密码，并且下载微博手机客户端保证能够扫码验证。

微博的爬虫目前为单线程。